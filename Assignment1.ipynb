{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTye/kmbrCblRN56vxUgkQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreyash007/deep_learning_course/blob/main/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 1 CS6910**\n",
        "Shreyash Gadgil (ED22S016)"
      ],
      "metadata": {
        "id": "9LINEVNo0Fo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login aa5afea12b4fda1e7f8310b597eb17c73d1176d2 #my API key for wandb login "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC2z2tS8Ccxo",
        "outputId": "7aa9678b-af1b-4aaa-b80c-cea584f30e72"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.10-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.15.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.25.1)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=a735c89b6c2b3c4c6a2da42da5f3d6de0f123597ee90e31b63c7947f344ee075\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, urllib3, smmap, setproctitle, docker-pycreds, sentry-sdk, gitdb, GitPython, wandb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.15.0 setproctitle-1.3.2 smmap-5.0.0 urllib3-1.26.14 wandb-0.13.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "G4iCjM7Q0SiV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "P0c3goK0vrQL"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1 SOLUTION\n",
        "Labelling dataset"
      ],
      "metadata": {
        "id": "a0Q5Mjvy0XZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "#importing dataset\n",
        "\n",
        "#checking size of training and test dataset\n",
        "print(\"Training dataset shape, X=\",X_train.shape,\", Y=\",Y_train.shape)\n",
        "print(\"Test dataset shape, X=\",X_test.shape,\", Y=\",Y_test.shape)\n",
        "\n",
        "n_img_classes=len(np.unique(Y_train)) #to find out number of unique images \n",
        "img_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] #taken from keras documentation\n",
        "\n",
        "\n",
        "def show_images(n_img_classes,img_labels,X,Y):\n",
        "\n",
        "   setImgs = []\n",
        "   setLabels=[]\n",
        "\n",
        "   for i in range(len(X)):\n",
        "     if len(setImgs)==n_img_classes:\n",
        "       break\n",
        "     if img_labels[Y[i]] not in setLabels:\n",
        "      setImgs.append(X[i])\n",
        "      setLabels.append(img_labels[Y[i]])\n",
        "\n",
        "   run=wandb.init(project='CS-6910 A1',entity='shreyashgadgil007',reinit=True)\n",
        "   run.log({\"Fashion_MNIST dataset\":list(wandb.Image(img,caption= caption) for img,caption in zip(setImgs,setLabels))})\n",
        "   run.finish()\n",
        "\n",
        "#---------------------------------------Q1 SOLUTION-------------------------------------------------------------------\n",
        "show_images(n_img_classes,img_labels,X_test,Y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "ZEPtktkP0cLG",
        "outputId": "7194ec0d-8896-418b-e2e7-4c3c7d4cc414"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Training dataset shape, X= (60000, 28, 28) , Y= (60000,)\n",
            "Test dataset shape, X= (10000, 28, 28) , Y= (10000,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshreyashgadgil007\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230225_054745-iz994538</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shreyashgadgil007/CS-6910%20A1/runs/iz994538' target=\"_blank\">gallant-fog-26</a></strong> to <a href='https://wandb.ai/shreyashgadgil007/CS-6910%20A1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shreyashgadgil007/CS-6910%20A1' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS-6910%20A1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shreyashgadgil007/CS-6910%20A1/runs/iz994538' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS-6910%20A1/runs/iz994538</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gallant-fog-26</strong> at: <a href='https://wandb.ai/shreyashgadgil007/CS-6910%20A1/runs/iz994538' target=\"_blank\">https://wandb.ai/shreyashgadgil007/CS-6910%20A1/runs/iz994538</a><br/>Synced 4 W&B file(s), 10 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230225_054745-iz994538/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing dataset for operations**\n",
        "1. Creating training,test,validation split for dataset\n",
        "2. Reshaping image matrix and normalizing pixel values\n",
        "3. One hot encoding classifications\n"
      ],
      "metadata": {
        "id": "ySDC6Ck0GjBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_preprocess():\n",
        "  #change the code below to accept different dataset\n",
        "  (X_1, Y_1), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "  \n",
        "  #importing dataset again and normalizing\n",
        "  X_1 = (X_1.reshape(X_1.shape[0],-1))/255.0\n",
        "  X_test = (X_test.reshape(X_test.shape[0],-1))/255.0\n",
        "\n",
        "  #training and validation split as specified in the question 10%\n",
        "  X_train, X_val, Y_train, Y_val= train_test_split(X_1,Y_1,test_size=0.1,random_state=0)\n",
        "  \n",
        "  #one hot encoding\n",
        "  Y_train_encoded=np.zeros((Y_train.shape[0],10))\n",
        "  for i in range(len(Y_train)):\n",
        "    Y_train_encoded[i][Y_train[i]]=1\n",
        "\n",
        "  Y_val_encoded=np.zeros((Y_val.shape[0],10))\n",
        "  for i in range(len(Y_val)):\n",
        "    Y_val_encoded[i][Y_val[i]]=1\n",
        "\n",
        "  Y_test_encoded=np.zeros((Y_test.shape[0],10))\n",
        "  for i in range(len(Y_test)):\n",
        "    Y_test_encoded[i][Y_test[i]]=1\n",
        "\n",
        "  return X_train,X_test,X_val,Y_train_encoded,Y_val_encoded,Y_test_encoded\n",
        "\n",
        "X_train,X_test,X_val,Y_train_encoded,Y_val_encoded,Y_test_encoded=dataset_preprocess()"
      ],
      "metadata": {
        "id": "IuMSSFIfGiZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feedforward neural network class"
      ],
      "metadata": {
        "id": "XCmVKBiE362R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------------------------------------------ACTIVATION FUNCTIONS AND THEIR GRADIENTS-------------------------------------------------------------------------------\n",
        "def relu(X):\n",
        "  return max(X,0)\n",
        "\n",
        "def grad_relu(X):\n",
        "  return X>0\n",
        "\n",
        "def sigmoid(X):\n",
        "  return 1/(1+np.exp(-X))\n",
        "\n",
        "def grad_sigmoid(X):\n",
        "  return sigmoid(X)(1-sigmoid(X))\n",
        "\n",
        "def tanh(X):\n",
        "  return (np.exp(X)-np.exp(-X))/(np.exp(X)+np.exp(-X))\n",
        "\n",
        "def grad_tanh(X):\n",
        "  return 1-(tanh(X))**2\n",
        "\n",
        "def softmax(X):\n",
        "  # Calculates the softmax function\n",
        "  e_X = np.exp(X - np.max(X, axis = 0))\n",
        "  return e_X / e_X.sum(axis = 0)\n",
        "\n",
        "def softmax_cross_entropy(Y,Y_pred):\n",
        "  return -(Y - Y_pred) \n",
        "\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------INITIALISATION FUNCTIONS------------------------------------------------------------------------------------------------\n",
        "def random_initialisation(shape):\n",
        "  # Initialising a random matrix with given dimensions (shape) as tuple\n",
        "  np.random.seed(0)\n",
        "  return np.random.randn(*shape)*0.1\n",
        "\n",
        "def xavier_initialisation(shape):\n",
        "    # Calculate the number of inputs and outputs\n",
        "    n_in = shape[0]\n",
        "    n_out = shape[1]\n",
        "    \n",
        "    # Calculate the variance of the normal distribution\n",
        "    variance = 2.0 / (n_in + n_out)\n",
        "    \n",
        "    # Initialize the weights with random values drawn from the normal distribution\n",
        "    np.random.seed(0)\n",
        "    weights = np.random.randn(n_in, n_out) * np.sqrt(variance)\n",
        "    \n",
        "    return weights\n",
        "\n",
        "#------------------------------------------------------------------INITIALIZING WEIGHTS AND BIASES------------------------------------------------------------------------------------\n",
        "def initialize_w_b(input_layer,hidden_layer,output_layer,init):\n",
        "  weights=[]\n",
        "  biases=[]\n",
        "  layers=[input_layer]+hidden_layer+[output_layer]\n",
        "  for i in range(len(hidden_layer)+1):\n",
        "     if init=='random':\n",
        "       weights.append(random_initialisation((layers[i],layers[i+1])))\n",
        "     if init=='xavier':\n",
        "       weights.append(xavier_initialisation((layers[i],layers[i+1])))\n",
        "     biases.append(np.random.randn(1,layers[i+1]))\n",
        "  return weights, biases\n",
        "\n",
        "\n",
        "#testing weights and biases output  \n",
        "output_layer = 10\n",
        "input_layer = X_test.shape[0]\n",
        "hidden_layer = [64, 64]\n",
        "weights, biases = initialize_w_b(input_layer, hidden_layer, output_layer, 'random')\n",
        "for i in range(len(weights)):\n",
        "    print(weights[i].shape)\n",
        "    \n",
        "for i in range(len(biases)):\n",
        "    print(biases[i].shape)\n",
        "print(weights[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIulf2iI377n",
        "outputId": "eaf063a6-3ddc-4e38-8eea-2788f98a0950"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 64)\n",
            "(64, 64)\n",
            "(64, 10)\n",
            "(1, 64)\n",
            "(1, 64)\n",
            "(1, 10)\n",
            "[ 0.01774261 -0.04017809 -0.16301983  0.04627823 -0.09072984  0.00519454\n",
            "  0.07290906  0.01289829  0.11394007 -0.12348258  0.04023416 -0.06848101\n",
            " -0.08707971 -0.05788497 -0.03115525  0.00561653 -0.11651498  0.09008265\n",
            "  0.04656624 -0.15362437  0.14882522  0.18958892  0.11787796 -0.01799248\n",
            " -0.10707526  0.10544517 -0.04031769  0.12224451  0.0208275   0.0976639\n",
            "  0.03563664  0.07065732  0.00105     0.17858705  0.01269121  0.04019894\n",
            "  0.18831507 -0.13477591 -0.1270485   0.09693967 -0.11731234  0.19436212\n",
            " -0.0413619  -0.07474548  0.1922942   0.14805148  0.1867559   0.09060447\n",
            " -0.08612257  0.1910065  -0.02680034  0.08024564  0.0947252  -0.01550101\n",
            "  0.06140794  0.09222067  0.03764255 -0.10994008  0.02982382  0.13263859\n",
            " -0.06945679 -0.01496345 -0.04351536  0.18492637]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_initialisation(shape):\n",
        "  # Initialising a random matrix with given dimensions (shape) as tuple\n",
        "  np.random.seed(0)\n",
        "  return np.random.randn(*shape)*0.1\n",
        "\n",
        "print(random_initialisation((1,2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QHPBlX6Q5gF",
        "outputId": "fc1b6277-cd42-4d6d-b798-a5a26f941404"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.17640523 0.04001572]]\n"
          ]
        }
      ]
    }
  ]
}